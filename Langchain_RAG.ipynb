{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xBvCE5v-Nxx"
      },
      "source": [
        "### LANGCHAIN\n",
        "参考： https://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG5A_FqzHITN"
      },
      "source": [
        "IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwSAPo8S3e-5"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai langchain-chroma bs4 pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E5DuuDR4Qje"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkpgJAVl6eTd"
      },
      "source": [
        "UPLOAD FILE\n",
        "\n",
        "https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt_X-dBS4Xvn"
      },
      "outputs": [],
      "source": [
        "# # WEB URL\n",
        "# bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
        "# loader = WebBaseLoader(\n",
        "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "#     bs_kwargs={\"parse_only\": bs4_strainer},\n",
        "# )\n",
        "# docs = loader.load()\n",
        "\n",
        "# print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOHSkKe58NGW",
        "outputId": "ff68a9b6-22fa-4a50-e6ab-2704949b394c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 37 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 73 0 (offset 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Style Transfer Final Project Report for CS-GY 6923_1_INET Machine Learning Yunge Wen, yw3776  Table of Content - Introduction - Convolutional Neural Network - VGG-19 Architecture & Feature Extraction - Neural Style Transfer  - Content Loss  - Gram Matrix & Style Loss  - Optimization - Next Steps: Vision Transformer and Segment Anything Model - Citations  Introduction  The groundbreaking research by Gatys et al. showcased the capabilities of Convolutional Neural Networks (CNNs) in generati\n"
          ]
        }
      ],
      "source": [
        "# PDF\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Final Project Report.pdf\")\n",
        "docs = loader.load()\n",
        "# pages = loader.load_and_split()\n",
        "print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPL9CP2G4Yr7"
      },
      "outputs": [],
      "source": [
        "# # TXT\n",
        "# from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# loader = TextLoader(\"/content/sample_data/README.md\")\n",
        "# docs = loader.load()\n",
        "\n",
        "# print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyLpNE-H9nJD"
      },
      "source": [
        "SPLIT TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OKbvutD6XjO",
        "outputId": "c623612a-de8d-413e-e9c7-e6e77d4c2fd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Style Transfer Final Project Report for CS-GY 6923_1_INET Machine Learning Yunge Wen, yw3776  Table of Content - Introduction - Convolutional Neural Network - VGG-19 Architecture & Feature Extraction - Neural Style Transfer  - Content Loss  - Gram Matrix & Style Loss  - Optimization - Next Steps: Vision Transformer and Segment Anything Model - Citations  Introduction  The groundbreaking research by Gatys et al. showcased the capabilities of Convolutional Neural Networks (CNNs) in generating artistic images by disentangling and recombining image content and style. This technique, known as Neural Style Transfer (NST), has since garnered significant attention in both academic circles and industrial applications.  In this project, I reproduced the seminal paper by visualizing the hidden layers of content and style feature maps within the neural network architecture step by step. Additionally, I propose leveraging NST in combination with the latest Segment Anything Model to achieve\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(splits[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH4HkE5x99Be"
      },
      "source": [
        "VECTOR EMBEDDING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKH8x2jG98mR"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTYf8xuFBDMs"
      },
      "source": [
        "RETRIEVAL ONLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5syfaohBEyl",
        "outputId": "37dfa359-0294-4dba-ec92-c408645593a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Style Transfer Final Project Report for CS-GY 6923_1_INET Machine Learning Yunge Wen, yw3776  Table of Content - Introduction - Convolutional Neural Network - VGG-19 Architecture & Feature Extraction - Neural Style Transfer  - Content Loss  - Gram Matrix & Style Loss  - Optimization - Next Steps: Vision Transformer and Segment Anything Model - Citations  Introduction  The groundbreaking research by Gatys et al. showcased the capabilities of Convolutional Neural Networks (CNNs) in generating artistic images by disentangling and recombining image content and style. This technique, known as Neural Style Transfer (NST), has since garnered significant attention in both academic circles and industrial applications.  In this project, I reproduced the seminal paper by visualizing the hidden layers of content and style feature maps within the neural network architecture step by step. Additionally, I propose leveraging NST in combination with the latest Segment Anything Model to achieve\n"
          ]
        }
      ],
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "retrieved_docs = retriever.invoke(\"What is CS-GY 6923_1_INET?\")\n",
        "print(retrieved_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kf7FPa1Fw10"
      },
      "source": [
        "PROMPTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkVtapC5DZmE",
        "outputId": "8b0d636b-db09-4784-b8f4-a965ae881fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: filler question \n",
            "Context: filler context \n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "# PROMPT\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
        ").to_messages()\n",
        "example_messages\n",
        "print(example_messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUS6SzarFyY7",
        "outputId": "31fe86b9-cbc2-47bb-c57b-2717de5987ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the question at the end.\n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "Use three sentences maximum and keep the answer as concise as possible.\n",
            "Always say \"thanks for asking!\" at the end of the answer.\n",
            "\n",
            "filler context\n",
            "\n",
            "Question: filler question\n",
            "\n",
            "Helpful Answer:\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "Always say \"thanks for asking!\" at the end of the answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "example_messages = custom_rag_prompt.invoke(\n",
        "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
        ").to_messages()\n",
        "example_messages\n",
        "print(example_messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9wNzq3pDZ8i"
      },
      "source": [
        "GENERATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU1I5bjnEbUF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmQU8qZTE2an",
        "outputId": "3ef0e560-6469-4b79-cb66-4286c3cef8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yunge Wen is the individual who authored the Neural Style Transfer Final Project Report for CS-GY 6923_1_INET Machine Learning, where they explored the capabilities of Convolutional Neural Networks in generating artistic images through disentangling and recombining image content and style. Yunge Wen is a student who reproduced the seminal paper by visualizing hidden layers of content and style feature maps within the neural network architecture and proposed leveraging Neural Style Transfer with the Segment Anything Model for enhanced visual effects."
          ]
        }
      ],
      "source": [
        "for chunk in rag_chain.stream(\"Who is Yunge?\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80JH9j01HavA",
        "outputId": "04e889b7-f8d0-421a-b546-6dd91287c451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CS-GY 6923_1_INET is a Machine Learning course that covers topics such as Convolutional Neural Networks, VGG-19 Architecture, Feature Extraction, and Neural Style Transfer. The course involves reproducing seminal papers in the field and exploring advanced techniques like leveraging Neural Style Transfer with the Segment Anything Model. It combines elements of art and research, making it a unique and interdisciplinary learning experience."
          ]
        }
      ],
      "source": [
        "for chunk in rag_chain.stream(\"What is CS-GY 6923_1_INET?\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tprQDrRcMf-O"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4xs8n3GN7T4"
      },
      "outputs": [],
      "source": [
        "# 官方 upload button\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def upload_file(files):\n",
        "    file_paths = [file.name for file in files]\n",
        "    return file_paths\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    file_output = gr.File()\n",
        "    upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\"image\", \"video\"], file_count=\"multiple\")\n",
        "    upload_button.upload(upload_file, upload_button, file_output)\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH6dVTN7Po1g"
      },
      "outputs": [],
      "source": [
        "# https://blog.csdn.net/qq_51116518/article/details/132628392\n",
        "\n",
        "import os\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "def generate_file(file_obj):\n",
        "    global tmpdir\n",
        "    print('临时文件夹地址：{}'.format(tmpdir))\n",
        "    print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址\n",
        "\n",
        "    #获取到上传后的文件的绝对路径后，其余的操作就和平常一致了\n",
        "\n",
        "    shutil.copy(file_obj.name, tmpdir)    # 将文件复制到临时目录中\n",
        "    FileName=os.path.basename(file_obj.name)     # 获取上传Gradio的文件名称\n",
        "    NewfilePath=os.path.join(tmpdir,FileName)     # 获取拷贝在临时目录的新的文件地址\n",
        "    print(NewfilePath)\n",
        "\n",
        "    # 打开复制到新路径后的文件\n",
        "    with open(NewfilePath, 'rb') as file_obj:\n",
        "\n",
        "        #在本地电脑打开一个新的文件，并且将上传文件内容写入到新文件\n",
        "        outputPath=os.path.join(tmpdir,\"New\"+FileName)\n",
        "        with open(outputPath,'wb') as w:\n",
        "            w.write(file_obj.read())\n",
        "\n",
        "    # 返回新文件的的地址（注意这里）\n",
        "    return outputPath\n",
        "\n",
        "def main():\n",
        "    global tmpdir\n",
        "    with tempfile.TemporaryDirectory(dir='.') as tmpdir:\n",
        "\n",
        "        inputs = gr.components.File(label=\"上传文件\")\n",
        "        outputs = gr.components.File(label=\"下载文件\")\n",
        "\n",
        "        app = gr.Interface(\n",
        "            fn=generate_file,\n",
        "            inputs=inputs,\n",
        "            outputs=outputs,\n",
        "            title=\"文件上传、并生成可下载文件demo\",\n",
        "            description=\"上传任何文件都可以，只要大小别超过你电脑的内存即可\"\n",
        "      )\n",
        "\n",
        "        app.launch(share=True)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAQnUtniVhdC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "file_obj = '/content/sample_data/README.md'\n",
        "\n",
        "global tmpdir\n",
        "print('临时文件夹地址：{}'.format(tmpdir))\n",
        "print('上传文件的地址：{}'.format(file_obj.name)) # 输出上传后的文件在gradio中保存的绝对地址"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32lCMHLxZCUI"
      },
      "outputs": [],
      "source": [
        "app = gr.Interface(\n",
        "    fn = None,\n",
        "    inputs = gr.components.File(label=\"上传文件\"),\n",
        "    outputs = None,\n",
        "    gr.components.Textbox()\n",
        ")\n",
        "\n",
        "app.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaRcYy_FiafZ"
      },
      "outputs": [],
      "source": [
        "gradio.Textbox(···)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5xBvCE5v-Nxx"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
